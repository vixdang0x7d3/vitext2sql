import streamlit as st
import pandas as pd
import time
import os
import sys
import glob
import io
import gzip
import base64
import chromadb
from datetime import datetime
from dotenv import load_dotenv
import json
import sqlite3

import traceback

# Th√™m th∆∞ m·ª•c g·ªëc v√†o path ƒë·ªÉ import c√°c module
load_dotenv()
root = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))

if root not in sys.path:
    sys.path.insert(0, root)

# Import c√°c module t·ª´ backend
try:
    from database_manager import DatabaseManager
    from llm_client import  create_vllm_client,GPTChat_sl
    from tokenizer import create_tokenizer
    from agent import Agent
    from pre.sqlite import extract_ddl_to_csv, export_all_tables_to_json
    from pre.setup_vector_chromadb import VietnameseRAGSystem
    from pre.retrive_external_context import retrieve_from_collections, save_prompt_context,check_if_question_relevant,VietnameseEmbedding
    from pre.reconstruct_data import compress_ddl
    from pre.schema_linking import ask_model_sl
    from pre.build_index import main
    # from pre.query_lsh import LSHChromaNormalizer
except ImportError as e:
    st.error(f"L·ªói import module: {e}")
    st.stop()
# ---- C·∫•u h√¨nh trang ----
st.set_page_config(
    page_title="SQL Agent Chat",
    layout="wide"
)
HISTORY_FILE = "chat_history.json"
# Kh·ªüi t·∫°o session state
if "current_db" not in st.session_state:
    st.session_state.current_db = None
if "messages" not in st.session_state:
    st.session_state.messages = []
if "new_messages" not in st.session_state:
    st.session_state.new_messages = []
if "agent" not in st.session_state:
    st.session_state.agent = None
if "dbman" not in st.session_state:
    st.session_state.dbman = None
if  "embedding_model" not in st.session_state:
    st.session_state.embedding_model = VietnameseEmbedding()

# ---- Kh·ªüi t·∫°o LLM Client ----
@st.cache_resource
def init_llm_client():
    """Kh·ªüi t·∫°o LLM client"""
    system_prompt = """\\no_think You are a data science expert that can write excellent SQL queries. Below, you are provided with a database schema, a natural question, and some necessary context. Your task is to understand the schema, the context, and generate a valid SQL query to answer the question.

    Instructions:
    - Make sure you only output the information that is asked in the question. If the question asks for a specific column, make sure to only include that column in the SELECT clause, nothing more.
    - The generated query should return all of the information asked in the question without any missing or extra information.
    - Before generating the final SQL query, please think through the steps of how to write the query.
    - For string-matching scenarios, if the string is decided, don't use fuzzy query. e.g. Get the object's title contains the word "book". However, if the string is not decided, you may use fuzzy query and ignore upper or lower case. e.g. Get articles that mention "education".
    - If the task description does not specify the number of decimal places, retain all decimals to four places.
    - For string-matching scenarios, convert non-standard symbols to '%'. e.g. ('he's to he%s)
    - When asked something without stating name or id, return both of them. e.g. Which products ...? The answer should include product_name and product_id.
    - When asked percentage decrease, you should return a positive value. e.g. How many percentage points in 2021 decrease compared to ...? The answer should be a positive value indicating the decreased number. Try to use ABS().
    - If asked two tables, you should reply with the last one instead of combining two tables. e.g. Identifying the top five states ... examine the state that ranks fourth overall and identify its top five counties. You should only answer top five counties.

    Take a deep breath and think step by step to find the correct SQL query.
    """
    system_prompt_sl = """
    You are a SQL schema-linking assistant.
    INSTRUCTIONS:
        - Input: You will be given only a subset of all available tables (e.g., 5 out of 10). Each table has schema information, and you are also given the natural-language task.
        - Output: For each provided table, decide whether it is needed to generate SQL for the task
 
    REQUIREMENTS:
        1. Do schema linking only with the given tables in the current request, but also consider that other related tables may exist outside this subset ,if you detect that a JOIN or foreign key reference points to a missing table, assume that missing table exists and take that table as related to the task .When uncertain, follow the principle "d∆∞ c√≤n h∆°n thi·∫øu" (prefer including possible relevant tables), but avoid unnecessary joins ‚Äî prefer correctness and minimality.
        2. Always include all four fields in your JSON object for each table:
            - "think": your reasoning in Vietnamese
            - "answer": "Y" or "N"
            - "columns": list of relevant columns (empty list if none)
            - "table name": the table's name
    
        3. If the answer is "Y", list the columns you think are relevant in a Python list format.
        4. Return a list of ** separate JSON object for each table** inside a single JSON code block. Do not merge multiple tables into one object.
        5. Do not include tables coming from the assistant role again in the output.

    Format example:

   ```json
    [
    {{
        "think": "B·∫£ng Customer ch·ª©a th√¥ng tin kh√°ch h√†ng, c√≥ th·ªÉ li√™n quan t·ªõi task ph√¢n t√≠ch h√†nh vi ng∆∞·ªùi d√πng.",
        "answer": "Y",
        "columns": ["CustomerID", "Name", "Address"],
        "table name": "Customer"
    }},
    {{
        "think": "B·∫£ng Order ch·ª©a th√¥ng tin ƒë∆°n h√†ng, li√™n quan ƒë·∫øn ph√¢n t√≠ch doanh s·ªë.",
        "answer": "Y",
        "columns": ["OrderID", "CustomerID", "OrderDate", "TotalAmount"],
        "table name": "Order"
    }},
    {{
        "think": "B·∫£ng Product c√≥ th√¥ng tin s·∫£n ph·∫©m, nh∆∞ng task kh√¥ng c·∫ßn d·ªØ li·ªáu s·∫£n ph·∫©m chi ti·∫øt.",
        "answer": "N",
        "columns": [],
        "table name": "Product"
    }}
    ]
```
"""
    try:
        # S·ª≠ d·ª•ng OpenAI client (c√≥ th·ªÉ thay ƒë·ªïi th√†nh Ollama n·∫øu c·∫ßn)
        # client = OpenAIClient(
        #     model="gpt-4.1",  # Thay ƒë·ªïi model ph√π h·ª£p
        #     temperature=1,
        #     max_context_length=200_000,
        #     system_prompt=system_prompt,
        # )

        
        
        sql_tokenizer = create_tokenizer("openai_compat", "qwen3-instruct")

        client = create_vllm_client(
            base_url=  "https://vixdang0x7d3--qwen3-server-serve.modal.run",
            model="llm", 
            max_context_length=128_000,
            tokenizer=sql_tokenizer,
            system_prompt=system_prompt,
        )
        # client_sl =  GPTChat_sl(system_prompt="",temperature=0)
        client_sl = GPTChat_sl(
            base_url="https://vixdang0x7d3--qwen3-server-serve.modal.run/v1", 
            model="llm",
            temperature=0.1,
            system_prompt=system_prompt_sl
        )

        

        # client = create_vllm_client(
        #     base_url=  "https://n21dccn176--qwen3-server-serve.modal.run",
        #     model="qwen3-8b", 
        #     max_context_length=128_000,
        #     tokenizer=sql_tokenizer,
        #     system_prompt=system_prompt,
        # )
      
        # client_sl = GPTChat_sl(
        #     base_url="https://n21dccn176--qwen3-server-serve.modal.run/v1", 
        #     model="qwen3-8b",
        #     temperature=0.1,
        #     system_prompt=system_prompt_sl
        # )
        return client,client_sl
    except Exception as e:
        st.error(f"L·ªói kh·ªüi t·∫°o LLM client: {e}")
        return None

# ---- H√†m setup database ----
def setup_database(db_name):
    """Setup database v√† c√°c file c·∫ßn thi·∫øt"""
    db_des = True
    db_folder = os.path.join("pre/db", db_name)
    db_path = os.path.join(db_folder, db_name + ".sqlite")
    
    
    if not os.path.exists(db_path):
        st.error(f"Kh√¥ng t√¨m th·∫•y file database: {db_path}")
        return None, None, False
    
    if not os.path.exists(os.path.join("./lsh_semantic", f"{db_name}_lsh_buckets.sqlite") ):
        st.info(f"ƒêang build index cho d·ªØ li·ªáu database: {db_name}")
        main(db_path=db_path,db_name=db_name,model=st.session_state.embedding_model)
        st.success(" Build xong index!")

    # T·∫°o schema path
    schema_path = os.path.join(db_folder, "schema")
    os.makedirs(schema_path, exist_ok=True)
    
    # Ki·ªÉm tra v√† t·∫°o DDL.csv
    ddl_path = os.path.join(schema_path, 'DDL.csv')
    if not os.path.exists(ddl_path):
        st.info("ƒêang t·∫°o DDL.csv...")
        try:
            extract_ddl_to_csv(db_folder,db_path,db_name, 'DDL.csv')
            st.success("ƒê√£ t·∫°o DDL.csv th√†nh c√¥ng!")
        except Exception as e:
            st.error(f"L·ªói t·∫°o DDL.csv: {e}")
    
    # Ki·ªÉm tra v√† t·∫°o JSON files
    json_files = glob.glob(os.path.join(schema_path, "*.json"))
    if not json_files:
        st.info("ƒêang xu·∫•t b·∫£ng th√†nh JSON...")
        try:
            result = export_all_tables_to_json(db_folder,db_path,
                db_name, 
                sample_limit=3
            )
            st.success("ƒê√£ xu·∫•t JSON th√†nh c√¥ng!")
        except Exception as e: 
            st.error(f"L·ªói xu·∫•t JSON: {e}")

    rag_system = VietnameseRAGSystem(st.session_state.embedding_model)
    chroma_client = chromadb.PersistentClient(path=os.path.join(db_folder, "db_chroma"))
    
    if not os.path.exists(os.path.join(db_folder,"prompts", db_name + ".txt")):
        st.info("ƒêang Compress schema...")
        try:
            # Compress DDL
            compress_ddl(db_folder,db_path,
            db_name=db_name,
            id=id,
            add_description=True,
            add_sample_rows=True,
            rm_digits=True,
            schema_linked=False,
            clear_long_eg_des=True,log_callback=None
        )   
             
            st.success("ƒê√£ Compress schema th√†nh c√¥ng!")
        except Exception as e:
            st.error(f"L·ªói Compress schema: {e}")
        st.info("ƒêang set up vector db cho schema db ...")
        try:
            rag_system.setup_vector_db_schema_db(db_name,db_folder)
   
            st.success("ƒê√£ set up vector db th√†nh c√¥ng!")
        except Exception as e:
            st.error(f"L·ªói set up vector db: {e}")
        
        
    # Ki·ªÉm tra vector database
    
    if "db_des" not in [col.name for col in chroma_client.list_collections()]:
        input_file = os.path.join(db_folder, "db_des", "db_des.txt")
        if os.path.exists(input_file):
            st.info("ƒêang t·∫°o vector database...")
            try:
                
                rag_system.setup_database(db_name,db_folder)
                st.success("ƒê√£ t·∫°o vector database th√†nh c√¥ng!")
            except Exception as e:
                st.error(f"L·ªói t·∫°o vector database: {e}")
        else:
            # st.warning("Database n√†y kh√¥ng c√≥ m√¥ t·∫£")
            db_des = False
    
    return db_folder, db_path, db_des

# ---- H√†m kh·ªüi t·∫°o agent ----
def init_agent(db_path, db_name, client):
    """Kh·ªüi t·∫°o database manager v√† agent"""
    try:
        # Kh·ªüi t·∫°o database manager
        dbman = DatabaseManager()
        dbman.start_sqlite(db_path)

        # Kh·ªüi t·∫°o agent
        agent = Agent(
            db_path=os.path.dirname(db_path),
            db_id=os.path.basename(db_path),
            db_manager=dbman,
            client=client,
        )
        
        # Health check
        agent.health_check()
        
        return agent, dbman
    except Exception as e:
        st.error(f"L·ªói kh·ªüi t·∫°o agent: {e}")
        return None, None

# ---- H√†m x·ª≠ l√Ω c√¢u h·ªèi ----
def process_question(id,db_folder,db_path,question, db_name, db_des,client,log_callback=None):
    """X·ª≠ l√Ω c√¢u h·ªèi v√† tr·∫£ v·ªÅ k·∫øt qu·∫£"""
    try:
        
        # Retrieve context
        desc_exemplars,_ = retrieve_from_collections(st.session_state.embedding_model,db_folder,db_path,db_des, question, db_name,log_callback=log_callback)
        
        # Save prompt context
        save_prompt_context(
            db_des,
            db_folder,
            db_path,
            results=desc_exemplars, 
            id=id, 
            db_name=db_name,log_callback=log_callback
        )
        
        # # Compress DDL
        # compress_ddl(db_folder,db_path,
        #     db_name=db_name,
        #     id=id,
        #     add_description=True,
        #     add_sample_rows=True,
        #     rm_digits=True,
        #     schema_linked=False,
        #     clear_long_eg_des=True,log_callback=log_callback
        # )
        # Schema linking
        ask_model_sl(
            db_folder,db_path,
            task=question,
            id=id,
            db_name=db_name,
            chat_session=client,
            log_callback=log_callback,
            model=st.session_state.embedding_model
        )
        
        # # ƒê·ªçc final context prompt
        # # db_folder = os.path.join("pre/db", db_name)
        # final_context_prompt_path = os.path.join(
        #     db_folder, 'final_context_prompts', str(id) + '.txt'
        # )
        
        # prompt_template = ""
        # with open(final_context_prompt_path, 'r', encoding='utf-8') as f:
        #     prompt_template = f.read()
        
        # # Ch·∫°y self-refine
        # self_refine_result = agent.self_refine(
        #     question=question,
        #     base_prompt=prompt_template
        # )
        
        return   id  
    except Exception as e:
        st.error(f"L·ªói x·ª≠ l√Ω c√¢u h·ªèi: {e}")
        traceback.print_exc()  # in full stack trace ra console
        return None, None
def self_refine(id,db_folder,question,agent,log_callback=None):
    # ƒê·ªçc final context prompt
    # db_folder = os.path.join("pre/db", db_name)
    print(id)
    final_context_prompt_path = os.path.join(
        db_folder, 'final_context_prompts', str(id) + '.txt'
    )
    
    prompt_template = ""
    with open(final_context_prompt_path, 'r', encoding='utf-8') as f:
        prompt_template = f.read()
    
    # Ch·∫°y self-refine
    self_refine_result = agent.self_refine(
        question=question,
        base_prompt=prompt_template,
        log_callback=log_callback
    )
    return self_refine_result

# def update_log(msg, logs,id,placeholder):
#     logs.append(msg)
#     placeholder.text_area(
#         "Processing Log", 
#         value="\n".join(logs), 
#         height=200, 
#         disabled=True
#     )   

def update_log(msg, logs, id, placeholder):
    if "logs_dict" not in st.session_state:
        st.session_state.logs_dict = {}
    if id not in st.session_state.logs_dict:
        st.session_state.logs_dict[id] = []
        
    st.session_state.logs_dict[id].append(msg)
    logs.append(msg)

    placeholder.text_area(
        "Processing Log", 
        value="\n".join(logs), 
        height=200, 
        disabled=True,
        # key=f"log_placeholder_{id}"
    )


def decode_dataframe(result):
    """Gi·∫£i n√©n dict k·∫øt qu·∫£ th√†nh DataFrame n·∫øu c·∫ßn"""
    if not result:
        return None
    if isinstance(result, dict) and "df_csv_data" in result:
        compressed_bytes = base64.b64decode(result["df_csv_data"])
        csv_data = gzip.decompress(compressed_bytes).decode("utf-8")
        if csv_data.strip() == "":
            return pd.DataFrame()
        return pd.read_csv(io.StringIO(csv_data))
    return result

def get_available_databases():
    db_root = "pre/db"
    return [
        name for name in os.listdir(db_root)
        if os.path.isdir(os.path.join(db_root, name))
    ]

client,client_sl = init_llm_client()
         
# ---- Thanh b√™n (Sidebar) ----
with st.sidebar:
    st.header(" Control Panel")
    # Upload database m·ªõi
    # uploaded_db = st.file_uploader("üì§ T·∫£i l√™n SQLite DB m·ªõi", type=["sqlite", "db"],key="file1")
    # if uploaded_db is not None:
    #     new_db_name = st.text_input("T√™n th∆∞ m·ª•c l∆∞u DB:", value=uploaded_db.name.split(".")[0])
    #     if st.button("‚ûï Th√™m DB"):
    #         new_db_folder = os.path.join("pre/db", new_db_name)
    #         os.makedirs(new_db_folder, exist_ok=True)
    #         db_path = os.path.join(new_db_folder, f"{new_db_name}.sqlite")
            
    #         with open(db_path, "wb") as f:
    #             f.write(uploaded_db.read())
            
    #         st.success(f"ƒê√£ th√™m DB m·ªõi: {new_db_name}")
    #         st.rerun()  # Load l·∫°i trang ƒë·ªÉ hi·ªán DB m·ªõi
    uploaded_file = st.file_uploader(
        "üì§ T·∫£i l√™n SQLite DB ho·∫∑c SQL m·ªõi",
        type=["sqlite", "db", "sql"],
        key="file1"
    )
    
    if uploaded_file is not None:
        # T√™n DB g·ªëc (kh√¥ng c√≥ ph·∫ßn ƒëu√¥i)
        base_name = uploaded_file.name.split(".")[0]
        
        # Th√™m timestamp ƒë·ªÉ t·∫°o t√™n folder duy nh·∫•t
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        new_db_name = st.text_input("T√™n th∆∞ m·ª•c l∆∞u DB:", value=f"{base_name}_{timestamp}")
        
        if st.button("‚ûï Th√™m DB"):
            new_db_folder = os.path.join("pre/db", new_db_name)
            os.makedirs(new_db_folder, exist_ok=True)
            
            # ƒê∆∞·ªùng d·∫´n file DB
            db_path = os.path.join(new_db_folder, f"{base_name}.sqlite")
            
            # N·∫øu l√† file SQLite ho·∫∑c DB th√¨ ghi tr·ª±c ti·∫øp
            if uploaded_file.name.endswith((".sqlite", ".db")):
                with open(db_path, "wb") as f:
                    f.write(uploaded_file.read())
                st.success(f"ƒê√£ th√™m DB SQLite m·ªõi: {new_db_name}")
            
            # N·∫øu l√† file SQL th√¨ t·∫°o DB t·ª´ SQL script
            elif uploaded_file.name.endswith(".sql"):
                sql_content = uploaded_file.read().decode("utf-8")  # ƒë·ªçc n·ªôi dung SQL
                connection = sqlite3.connect(db_path)
                cursor = connection.cursor()
                cursor.executescript(sql_content)  # ch·∫°y to√†n b·ªô script
                connection.commit()
                connection.close()
                st.success(f"ƒê√£ t·∫°o DB m·ªõi t·ª´ file SQL: {new_db_name}")
            
            st.rerun()  # Load l·∫°i trang ƒë·ªÉ hi·ªán DB m·ªõi

    available_dbs = get_available_databases()
    # Ch·ªçn database
    db_name = st.selectbox(
        " Ch·ªçn Database",
        available_dbs,
        help="Ch·ªçn database ƒë·ªÉ l√†m vi·ªác"
    )
    # Setup database khi thay ƒë·ªïi
    if st.session_state.current_db != db_name:
        st.session_state.current_db = db_name
        st.session_state.agent = None
        st.session_state.dbman = None

        #  Append chat m·ªõi v√†o l·ªãch s·ª≠
        new_chats = st.session_state.new_messages or []
        st.session_state.new_messages=[]
        if new_chats:
           
            history_chat_folder = os.path.join(st.session_state.db_folder,"history_chat")
            os.makedirs(history_chat_folder, exist_ok=True)
            history_chat_file = os.path.join(history_chat_folder,HISTORY_FILE)

            if os.path.exists(history_chat_file):
                try:
                    with open(history_chat_file, "r", encoding="utf-8") as f:
                        chat_history = json.load(f)
                except:
                    chat_history = []
            else:
                chat_history = []

            chat_history.extend(new_chats)

            # L∆∞u l·∫°i v√†o file
            with open(history_chat_file, "w", encoding="utf-8") as f:
                json.dump(chat_history, f, ensure_ascii=False, indent=2)

        with st.spinner("ƒêang setup database..."):
            db_folder, db_path, db_des = setup_database(db_name)
            
            if db_path:
                st.session_state.db_folder = db_folder
                st.session_state.db_path = db_path
                st.session_state.db_des = db_des
                st.success(f" Database {db_name} ƒë√£ s·∫µn s√†ng!")

    
    if not st.session_state.db_des:
        st.warning("Database n√†y ch∆∞a c√≥ m√¥ t·∫£.")
        # breakpoint()
        uploaded_desc = st.file_uploader("üìÑ T·∫£i l√™n file m√¥ t·∫£ (.txt)", type=["txt"],key="file2")
        # print(uploaded_desc)
        if uploaded_desc is not None:
            print("1")
            db_des_folder = os.path.join(st.session_state.db_folder, "db_des")
            os.makedirs(db_des_folder, exist_ok=True)
            desc_path = os.path.join(db_des_folder, "db_des.txt")
            
            with open(desc_path, "wb") as f:
                f.write(uploaded_desc.read())
            
            st.success("ƒê√£ th√™m m√¥ t·∫£ cho database!")
            
            # T·∫°o l·∫°i vector database sau khi c√≥ m√¥ t·∫£
            try:
                st.info("ƒêang t·∫°o vector database...")
                rag_system = VietnameseRAGSystem(st.session_state.embedding_model)
                rag_system.setup_database(db_name,st.session_state.db_folder)
                st.success("Vector database ƒë√£ ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng!")
                st.session_state.db_des = True
            except Exception as e:
                st.error(f"L·ªói t·∫°o vector database: {e}")            
    # Kh·ªüi t·∫°o LLM client v√† agent
    if st.button(" Kh·ªüi t·∫°o Agent"):
        with st.spinner("ƒêang kh·ªüi t·∫°o LLM client v√† agent..."):
            history_chat_folder = os.path.join(st.session_state.db_folder,"history_chat")
            os.makedirs(history_chat_folder, exist_ok=True)
            history_chat_file = os.path.join(history_chat_folder,HISTORY_FILE)

            if os.path.exists(history_chat_file):
                try:
                    with open(history_chat_file, "r", encoding="utf-8") as f:
                        chat_history = json.load(f)
                except:
                    chat_history = []
            else:
                chat_history = []

            st.session_state.messages = chat_history
            # client = init_llm_client()
            print(st.session_state.db_path)
            if client:
                agent, dbman = init_agent(
                    st.session_state.db_path, 
                    db_name, 
                    client
                )
                if agent:
                    st.session_state.agent = agent
                    st.session_state.dbman = dbman
                    st.success(" Agent ƒë√£ s·∫µn s√†ng!")
                else:
                    st.error(" L·ªói kh·ªüi t·∫°o agent")
            else:
                st.error(" L·ªói kh·ªüi t·∫°o LLM client")
    
    # Hi·ªÉn th·ªã tr·∫°ng th√°i
    st.markdown("---")
    st.subheader(" Status")
    if st.session_state.current_db:
        st.success(f"DB: {st.session_state.current_db}")
    if st.session_state.agent:
        st.success("Agent:  Ready")
    else:
        st.warning("Agent:  Not initialized")

# ---- Giao di·ªán ch√≠nh ----
st.title("ü§ñ SQL Agent Chat")
st.markdown("H·ªèi ƒë√°p v·ªõi database b·∫±ng ng√¥n ng·ªØ t·ª± nhi√™n")

# Ki·ªÉm tra agent ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o ch∆∞a
if not st.session_state.agent:
    st.warning(" Vui l√≤ng kh·ªüi t·∫°o Agent t·ª´ sidebar tr∆∞·ªõc khi s·ª≠ d·ª•ng!")
    st.stop()

# Hi·ªÉn th·ªã c√°c tin nh·∫Øn ƒë√£ c√≥ trong l·ªãch s·ª≠
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        if isinstance(message["content"], dict):
            # Hi·ªÉn th·ªã ph·∫£n h·ªìi c·ªßa assistant
            st.subheader("üìã Log:")
            # D√πng expander thay cho text_area
            with st.expander("Processing Log", expanded=False):
                log_text = message["content"]["log_body"]
                st.markdown(log_text)

            st.subheader("üîç Final SQL:")
            st.code(message["content"]["sql_body"], language="sql")
            results_data = message["content"]["results_data"]

            # N·∫øu l√† list[dict] th√¨ convert l·∫°i th√†nh DataFrame
            if isinstance(results_data, list) and all(isinstance(row, dict) for row in results_data):
                results_data = pd.DataFrame(results_data)
            st.markdown("---")
            st.subheader(" Query Results:")
            if isinstance(results_data, pd.DataFrame):
                st.dataframe(results_data, use_container_width=True, hide_index=True)
            else:
                st.write(results_data)
        else:
            # Tin nh·∫Øn c·ªßa user
            st.markdown(message["content"])




# ---- √î nh·∫≠p li·ªáu chat ----
prompt = st.chat_input("üí¨ Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n ·ªü ƒë√¢y...")

if prompt:
    # Th√™m tin nh·∫Øn c·ªßa user
    with st.chat_message("user"):
        st.markdown(prompt)

    is_relevant  = check_if_question_relevant(st.session_state.embedding_model,st.session_state.db_folder,st.session_state.db_path,st.session_state.db_des, prompt, db_name,top_k=5,distance_threshold=0.57)
    
    
    if is_relevant:
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.session_state.new_messages.append({"role": "user", "content": prompt})

        # X·ª≠ l√Ω v√† tr·∫£ l·ªùi
        with st.chat_message("assistant"):
            with st.spinner("ü§î Scheama linking and Self refine..."):
                st.subheader("üìã Log:")
                # log_placeholder = st.empty()  # Placeholder cho log real-time
                expander_placeholder = st.empty()
                logs = []  # L∆∞u log t·∫°m th·ªùi
                id = int(time.time())
                thinking_container = st.container()
                if "expander_states" not in st.session_state:
                     st.session_state.expander_states = {}

                def update_thinking_log(msg, logs, id, container):
                    """Update log trong thinking section"""
                    
                    timestamp = datetime.now().strftime('%H:%M:%S')
                    
                    # Th√™m icon t∆∞∆°ng ·ª©ng v·ªõi lo·∫°i message
                    if "th√†nh c√¥ng" in msg.lower() or "‚úÖ" in msg:
                        icon = "‚úÖ"
                    elif "l·ªói" in msg.lower() or "‚ùå" in msg:
                        icon = "‚ùå"
                    elif "ƒëang" in msg.lower():
                        icon = "‚è≥"
                    else:
                        icon = "üí≠"
                        
                    formatted_msg = f"\n{icon} [{timestamp}] {msg}"
                    logs.append(formatted_msg)
                    

                    # C·∫≠p nh·∫≠t thinking section
                    with container:
                        with expander_placeholder.expander(f"{msg} ", expanded=True):
                         
                            log_text = "\n".join(logs)
                            st.markdown(log_text)
                
                _ = process_question(
                    id,
                    st.session_state.db_folder,
                    st.session_state.db_path,
                    prompt, 
                    st.session_state.current_db, 
                    st.session_state.db_des, 
                    client_sl,
                    log_callback=lambda msg: update_thinking_log(msg, logs, id, thinking_container)
                )
                
                success, final_result, final_sql, log_text = self_refine(
                    id,
                    st.session_state.db_folder,
                    prompt,
                    st.session_state.agent,
                    log_callback=lambda msg: update_thinking_log(msg, logs, id, thinking_container)
                )            
                # X·ª≠ l√Ω c√¢u h·ªèi
                # _ = process_question(
                #     id,
                #     st.session_state.db_folder,
                #     st.session_state.db_path,
                #     prompt, 
                #     st.session_state.current_db, 
                #     st.session_state.db_des, 
                #     client_sl,
                #     log_callback=lambda msg: update_log(msg,logs,id, log_placeholder)
                # )
                
                # success, final_result, final_sql, log_text = self_refine(
                #     id,
                #     st.session_state.db_folder,
                #     prompt,
                #     st.session_state.agent,
                #     log_callback=lambda msg: update_log(msg, logs,id, log_placeholder)
                # )


                if success:
                    # T·∫°o n·ªôi dung ph·∫£n h·ªìi
                    assistant_response = {
                        "id": id,
                        "log_body": "",
                        "sql_body": final_sql or "-- Kh√¥ng c√≥ SQL ƒë∆∞·ª£c t·∫°o",
                        "results_data": final_result
                    }
                    
                    # # Hi·ªÉn th·ªã log cu·ªëi c√πng
                    
                    # update_log( "ƒê√£ x·ª≠ l√Ω th√†nh c√¥ng!", logs,id,log_placeholder)
                    update_thinking_log(" ƒê√£ x·ª≠ l√Ω th√†nh c√¥ng!", logs, id, thinking_container)
                    # st.text_area(
                    #     "Processing Log", 
                    #     value="\n".join(logs), 
                    #     height=150, 
                    #     key=f"current_log_{assistant_response['id']}",
                    #     disabled=True
                    # )
                    assistant_response["log_body"] = "\n".join(logs)

                    st.subheader(" Final SQL:")
                    st.code(assistant_response["sql_body"], language="sql")

            

                    # --- Trong ph·∫ßn hi·ªÉn th·ªã ---
                    st.markdown("---")
                    st.subheader(" Query Results:")
                    results_data = decode_dataframe(assistant_response["results_data"])

                    if results_data is not None:
                        if isinstance(results_data, pd.DataFrame):
                            st.dataframe(
                                results_data, 
                                use_container_width=True, 
                                hide_index=True
                            )
                            assistant_response["results_data"] = results_data.to_dict(orient="records")
                        else:
                            st.write(results_data)
                            assistant_response["results_data"] = results_data
                    else:
                        st.info("Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ hi·ªÉn th·ªã")
                        assistant_response["results_data"] = None

                    # L∆∞u v√†o l·ªãch s·ª≠
                    st.session_state.messages.append({
                        "role": "assistant", 
                        "content": assistant_response
                    })
                    st.session_state.new_messages.append({
                        "role": "assistant", 
                        "content": assistant_response
                    })

                else:
                    st.error("C√≥ l·ªói x·∫£y ra khi x·ª≠ l√Ω c√¢u h·ªèi!")
    else:
        with st.chat_message("assistant"):
            st.warning("C√¢u h·ªèi n√†y kh√¥ng li√™n quan ƒë·∫øn c∆° s·ªü d·ªØ li·ªáu hi·ªán t·∫°i.")
            st.info("üí° B·∫°n c√≥ th·ªÉ:")
            st.markdown("""
            - ƒê·∫∑t c√¢u h·ªèi kh√°c li√™n quan ƒë·∫øn **database hi·ªán t·∫°i**.
            - Ho·∫∑c ch·ªçn l·∫°i **database** kh√°c ph√π h·ª£p h∆°n.
            """)
            
            # G·ª£i √Ω n·∫øu mu·ªën
            # related_topics = get_related_topics(db_folder, top_k=3)
            related_topics=["C·∫ßu th·ªß 'P002' ƒë√£ ƒë√°nh ƒë∆∞·ª£c bao nhi√™u home run trong giai ƒëo·∫°n h·∫≠u m√πa gi·∫£i nƒÉm 2024?","C·∫ßu th·ªß 'P003' ƒë√£ h·ªçc t·∫°i tr∆∞·ªùng ƒë·∫°i h·ªçc n√†o v√†o nƒÉm 2010?","ERA trung b√¨nh c·ªßa c√°c c·∫ßu th·ªß trong ƒë·ªôi 'T001' cho m√πa gi·∫£i 2024 l√† bao nhi√™u?"]
            if related_topics:
                st.subheader("üîç Ch·ªß ƒë·ªÅ g·ª£i √Ω:")
                for topic in related_topics:
                    st.write(f"- {topic}")  
# ---- Footer ----
st.markdown("---")
st.markdown(" **SQL Agent Chat** - Powered by AI")